{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Exploration Notebook\n",
        "\n",
        "## Introduction\n",
        "\n",
        "This notebook provides comprehensive exploratory data analysis (EDA) for deepfake detection datasets. We'll analyze:\n",
        "\n",
        "1. Dataset structure and organization\n",
        "2. Class distribution (real vs fake)\n",
        "3. Image statistics (resolution, aspect ratio, file formats)\n",
        "4. Face detection success rates\n",
        "5. Dataset quality metrics\n",
        "\n",
        "## Dataset Description\n",
        "\n",
        "The dataset contains images labeled as either \"real\" or \"fake\" (deepfake). We'll explore various aspects to understand the data distribution and quality.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Project root added: c:\\Users\\HP\\Documents\\QUEST\\dfprojectv2\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Resolve project root (dfprojectv2)\n",
        "project_root = Path().resolve().parent.parent\n",
        "\n",
        "# Add project root to path (robust)\n",
        "project_root = Path(__file__).resolve().parents[1] if \"__file__\" in globals() else Path.cwd().parents[0]\n",
        "\n",
        "if str(project_root) not in sys.path:\n",
        "    sys.path.insert(0, str(project_root))\n",
        "\n",
        "print(\"Project root added:\", project_root)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Libraries imported successfully!\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "\n",
        "# Add project root to path\n",
        "project_root = Path().resolve().parent.parent\n",
        "sys.path.append(str(project_root))\n",
        "\n",
        "# Import EDA modules\n",
        "from eda.data_analyzer import DataAnalyzer\n",
        "from eda.visualization import EDAVisualizer\n",
        "\n",
        "# Set style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"Set2\")\n",
        "%matplotlib inline\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EDA package imports working correctly\n"
          ]
        }
      ],
      "source": [
        "from eda import DataAnalyzer, DataQualityChecker, EDAVisualizer\n",
        "print(\"EDA package imports working correctly\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Dataset Configuration\n",
        "\n",
        "Configure the dataset path and initialize the analyzer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset path: C:\\Users\\HP\\Documents\\QUEST\\deepfake project\\dataset\n",
            "Dataset exists: True\n"
          ]
        }
      ],
      "source": [
        "# Configure dataset path\n",
        "DATASET_PATH = r\"C:\\Users\\HP\\Documents\\QUEST\\deepfake project\\dataset\"  # Update this to your dataset path\n",
        "DATASET_NAME = \"faceforensics\"  # faceforensics, celebdf, dfdc\n",
        "\n",
        "# Initialize analyzer and visualizer\n",
        "analyzer = DataAnalyzer(DATASET_PATH)\n",
        "visualizer = EDAVisualizer()\n",
        "\n",
        "print(f\"Dataset path: {DATASET_PATH}\")\n",
        "print(f\"Dataset exists: {os.path.exists(DATASET_PATH)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'DataAnalyzer' object has no attribute 'get_class_distribution'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m class_counts \u001b[38;5;241m=\u001b[39m \u001b[43manalyzer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_class_distribution\u001b[49m()\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'DataAnalyzer' object has no attribute 'get_class_distribution'"
          ]
        }
      ],
      "source": [
        "class_counts = analyzer.get_class_distribution()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'class_counts' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m visualizer\u001b[38;5;241m.\u001b[39mplot_class_distribution(\u001b[43mclass_counts\u001b[49m, interactive\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'class_counts' is not defined"
          ]
        }
      ],
      "source": [
        "visualizer.plot_class_distribution(class_counts, interactive=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Dataset Structure Analysis\n",
        "\n",
        "Analyze the directory structure and organization of the dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze dataset structure\n",
        "structure = analyzer.analyze_dataset_structure()\n",
        "\n",
        "print(\"=== Dataset Structure ===\")\n",
        "print(f\"Total Images: {structure['total_images']}\")\n",
        "print(f\"Classes: {structure['classes']}\")\n",
        "print(f\"File Formats: {dict(structure['file_formats'])}\")\n",
        "print(f\"Corrupted Files: {len(structure['corrupted_files'])}\")\n",
        "\n",
        "# Display structure\n",
        "structure\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Class Distribution Analysis\n",
        "\n",
        "Analyze the distribution of real vs fake images.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze class distribution\n",
        "class_dist = analyzer.analyze_class_distribution()\n",
        "\n",
        "print(\"=== Class Distribution ===\")\n",
        "print(f\"Total Images: {class_dist['total']}\")\n",
        "print(f\"Real: {class_dist['counts']['real']} ({class_dist['percentages']['real']:.2f}%)\")\n",
        "print(f\"Fake: {class_dist['counts']['fake']} ({class_dist['percentages']['fake']:.2f}%)\")\n",
        "print(f\"Imbalance Ratio: {class_dist['imbalance_ratio']:.2f}\")\n",
        "\n",
        "# Visualize class distribution\n",
        "fig = visualizer.plot_class_distribution(\n",
        "    class_dist['counts'],\n",
        "    save_path=\"../reports/visualizations/class_distribution.png\",\n",
        "    interactive=True\n",
        ")\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Image Statistics\n",
        "\n",
        "Analyze image resolutions, aspect ratios, and other image properties.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze image statistics (sample 1000 images for speed)\n",
        "img_stats = analyzer.analyze_image_statistics(sample_size=1000)\n",
        "\n",
        "print(\"=== Image Statistics ===\")\n",
        "print(f\"Mean Resolution: {img_stats['resolutions']['mean']:.0f} x {img_stats['resolutions']['mean']:.0f}\")\n",
        "print(f\"Resolution Std: {img_stats['resolutions']['std']:.2f}\")\n",
        "print(f\"Min Resolution: {img_stats['resolutions']['min']}\")\n",
        "print(f\"Max Resolution: {img_stats['resolutions']['max']}\")\n",
        "print(f\"Mean Aspect Ratio: {img_stats['aspect_ratios']['mean']:.2f}\")\n",
        "\n",
        "# Visualize resolution distribution\n",
        "if img_stats['resolutions']['distribution']:\n",
        "    fig = visualizer.plot_resolution_distribution(\n",
        "        img_stats['resolutions']['distribution'],\n",
        "        save_path=\"../reports/visualizations/resolution_distribution.png\",\n",
        "        interactive=True\n",
        "    )\n",
        "    fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Dataset Quality Assessment\n",
        "\n",
        "Calculate overall dataset quality score and get recommendations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate quality score\n",
        "quality = analyzer.calculate_dataset_quality_score()\n",
        "\n",
        "print(\"=== Dataset Quality Score ===\")\n",
        "print(f\"Overall Score: {quality['overall_score']:.2f}/1.0\")\n",
        "print(\"\\nQuality Factors:\")\n",
        "for factor, value in quality['factors'].items():\n",
        "    print(f\"  {factor}: {value:.2f}\")\n",
        "\n",
        "print(\"\\n=== Recommendations ===\")\n",
        "for i, rec in enumerate(quality['recommendations'], 1):\n",
        "    print(f\"{i}. {rec}\")\n",
        "\n",
        "quality\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Save Statistics\n",
        "\n",
        "Save all statistics for later use.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save statistics\n",
        "os.makedirs(\"../reports/statistics\", exist_ok=True)\n",
        "analyzer.save_statistics(f\"../reports/statistics/dataset_stats_{DATASET_NAME}.json\")\n",
        "\n",
        "print(\"Statistics saved successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Automated EDA Report Generation\n",
        "\n",
        "Generate a comprehensive EDA report using the automated report generator.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate automated EDA report\n",
        "from eda.report_generator import generate_eda_report\n",
        "\n",
        "report_path = generate_eda_report(\n",
        "    dataset_path=DATASET_PATH,\n",
        "    output_format='html',\n",
        "    output_dir='../reports',\n",
        "    dataset_name=DATASET_NAME\n",
        ")\n",
        "\n",
        "print(f\"EDA report generated at: {report_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Data Quality Assessment\n",
        "\n",
        "Use DataQualityChecker to assess dataset quality.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Assess dataset quality using DataQualityChecker\n",
        "from eda.data_analyzer import DataQualityChecker\n",
        "\n",
        "checker = DataQualityChecker()\n",
        "quality_assessment = checker.assess_dataset(DATASET_PATH)\n",
        "\n",
        "print(\"=== Dataset Quality Assessment ===\")\n",
        "print(f\"Overall Quality Score: {quality_assessment['overall_score']:.2f}/1.0\")\n",
        "print(f\"Quality Level: {quality_assessment['quality_level']}\")\n",
        "print(f\"Dataset Size: {quality_assessment['dataset_size']} images\")\n",
        "print(f\"Class Balance Ratio: {quality_assessment['class_balance']:.2f}\")\n",
        "print(f\"Corrupted Files: {quality_assessment['corrupted_files']}\")\n",
        "\n",
        "print(\"\\n=== Quality Factors ===\")\n",
        "for factor, value in quality_assessment['quality_factors'].items():\n",
        "    print(f\"{factor}: {value:.2f}\")\n",
        "\n",
        "print(\"\\n=== Recommendations ===\")\n",
        "for i, rec in enumerate(quality_assessment['recommendations'], 1):\n",
        "    print(f\"{i}. {rec}\")\n",
        "\n",
        "quality_assessment\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
