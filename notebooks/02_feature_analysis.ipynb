{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Feature Analysis Notebook\n",
        "\n",
        "## Introduction\n",
        "\n",
        "This notebook analyzes deepfake-specific features including frequency domain analysis, noise patterns, color consistency, texture analysis, and dimensionality reduction visualizations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from scipy.fft import dct\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "project_root = Path().resolve().parent.parent\n",
        "sys.path.append(str(project_root))\n",
        "\n",
        "from eda.visualization import EDAVisualizer\n",
        "from eda.artifact_detector import ArtifactDetector\n",
        "\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Sample Images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load sample real and fake images\n",
        "DATASET_PATH = \"../data/raw\"\n",
        "\n",
        "# Example: Load images (implement your loading logic)\n",
        "import os\n",
        "from pathlib import Path\n",
        "import cv2\n",
        "\n",
        "real_images = []\n",
        "fake_images = []\n",
        "\n",
        "real_dir = Path(DATASET_PATH) / \"real\"\n",
        "fake_dir = Path(DATASET_PATH) / \"fake\"\n",
        "\n",
        "if real_dir.exists():\n",
        "    for img_file in list(real_dir.glob(\"*.jpg\"))[:10] + list(real_dir.glob(\"*.png\"))[:10]:\n",
        "        img = cv2.imread(str(img_file))\n",
        "        if img is not None:\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            real_images.append(img)\n",
        "\n",
        "if fake_dir.exists():\n",
        "    for img_file in list(fake_dir.glob(\"*.jpg\"))[:10] + list(fake_dir.glob(\"*.png\"))[:10]:\n",
        "        img = cv2.imread(str(img_file))\n",
        "        if img is not None:\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            fake_images.append(img)\n",
        "\n",
        "print(f\"Loaded {len(real_images)} real and {len(fake_images)} fake images\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Frequency Domain Analysis\n",
        "\n",
        "Compare frequency spectra between real and fake images.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare frequency spectra using DCT\n",
        "visualizer = EDAVisualizer()\n",
        "\n",
        "# Select sample images\n",
        "if len(real_images) > 0 and len(fake_images) > 0:\n",
        "    real_sample = real_images[0]\n",
        "    fake_sample = fake_images[0]\n",
        "    \n",
        "    # Plot frequency comparison using DCT\n",
        "    fig = visualizer.plot_frequency_comparison(\n",
        "        real_sample, fake_sample,\n",
        "        save_path=\"../reports/visualizations/frequency_comparison_dct.png\"\n",
        "    )\n",
        "    plt.show()\n",
        "    \n",
        "    # Alternative: Direct DCT spectrum plot\n",
        "    fig = visualizer.plot_frequency_spectrum(\n",
        "        real_sample, fake_sample,\n",
        "        save_path=\"../reports/visualizations/frequency_spectrum_dct.png\"\n",
        "    )\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No images loaded. Please check dataset path.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Statistical Distribution Comparison\n",
        "\n",
        "Compare distributions between real and fake images using statistical tests.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare distributions using the new compare_distributions function\n",
        "from eda.statistical_tests import compare_distributions\n",
        "\n",
        "if len(real_images) > 0 and len(fake_images) > 0:\n",
        "    # Compare pixel distributions\n",
        "    p_value = compare_distributions(\n",
        "        real_images[:50],  # Sample for speed\n",
        "        fake_images[:50],\n",
        "        test_type='ks',  # Kolmogorov-Smirnov test\n",
        "        alpha=0.05\n",
        "    )\n",
        "    \n",
        "    print(f\"Kolmogorov-Smirnov test p-value: {p_value}\")\n",
        "    \n",
        "    # Run all tests\n",
        "    all_results = compare_distributions(\n",
        "        real_images[:50],\n",
        "        fake_images[:50],\n",
        "        test_type='all',\n",
        "        alpha=0.05\n",
        "    )\n",
        "    \n",
        "    print(\"\\nAll statistical test results:\")\n",
        "    for test_name, result in all_results.items():\n",
        "        print(f\"{test_name}:\")\n",
        "        print(f\"  p-value: {result['p_value']:.4f}\")\n",
        "        print(f\"  Significant: {result['significant']}\")\n",
        "        print(f\"  Interpretation: {result['interpretation']}\")\n",
        "else:\n",
        "    print(\"No images loaded.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Feature Importance Analysis\n",
        "\n",
        "Analyze which artifact features are most important for deepfake detection.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze feature importance\n",
        "from eda.difficulty_estimator import FeatureImportanceAnalyzer\n",
        "\n",
        "if len(real_images) > 0 and len(fake_images) > 0:\n",
        "    importance_analyzer = FeatureImportanceAnalyzer()\n",
        "    importance_results = importance_analyzer.analyze_feature_importance(\n",
        "        real_images[:50],\n",
        "        fake_images[:50]\n",
        "    )\n",
        "    \n",
        "    print(\"=== Feature Importance Analysis ===\")\n",
        "    print(\"\\nImportance Scores:\")\n",
        "    for feature, score in importance_results['importance_scores'].items():\n",
        "        print(f\"  {feature}: {score:.3f}\")\n",
        "    \n",
        "    print(f\"\\nMost Important Feature: {importance_results['most_important']}\")\n",
        "    \n",
        "    print(\"\\nRecommendations:\")\n",
        "    for rec in importance_results['recommendations']:\n",
        "        print(f\"  - {rec}\")\n",
        "else:\n",
        "    print(\"No images loaded.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Data Difficulty Estimation\n",
        "\n",
        "Estimate how difficult the dataset is for deepfake detection.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Estimate dataset difficulty\n",
        "from eda.difficulty_estimator import DataDifficultyEstimator\n",
        "\n",
        "if len(real_images) > 0 and len(fake_images) > 0:\n",
        "    difficulty_estimator = DataDifficultyEstimator()\n",
        "    difficulty_results = difficulty_estimator.estimate_difficulty(\n",
        "        real_images[:100],\n",
        "        fake_images[:100]\n",
        "    )\n",
        "    \n",
        "    print(\"=== Data Difficulty Estimation ===\")\n",
        "    print(f\"Difficulty Score: {difficulty_results['difficulty_score']:.3f} (0=Easy, 1=Hard)\")\n",
        "    print(f\"Difficulty Level: {difficulty_results['difficulty_level']}\")\n",
        "    print(f\"Artifact Visibility: {difficulty_results['artifact_visibility']:.3f}\")\n",
        "    print(f\"Statistical Separability: {difficulty_results['statistical_separability']:.3f}\")\n",
        "    \n",
        "    print(\"\\nRecommendations:\")\n",
        "    for rec in difficulty_results['recommendations']:\n",
        "        print(f\"  - {rec}\")\n",
        "else:\n",
        "    print(\"No images loaded.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
